{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from stable_baselines3 import PPO\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trail import TrailEnv\n",
    "from trail_map import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_discrete = True\n",
    "global_treadmill = True\n",
    "trail_class = MeanderTrail\n",
    "# trail_args = {'width': 3, 'length': 69, 'radius': 100, 'diff_rate': 0.04, 'breaks': [(0.5, 0.8)]}\n",
    "trail_args = {\n",
    "    'width': 5, \n",
    "    'length': 90, \n",
    "    'radius': 100, \n",
    "    'diff_rate': 0.01, \n",
    "    'reward_dist': 3,\n",
    "    # 'breaks':[(0.5, 0.62)]\n",
    "    # 'breaks':[(0.5, 0.8)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single run\n",
    "\n",
    "trail_map = trail_class(**trail_args, heading=0)\n",
    "env = TrailEnv(trail_map, discrete=global_discrete, treadmill=global_treadmill)\n",
    "model = PPO.load('trail_model.zip', device='cpu')\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, is_done, _ = env.step(action)\n",
    "\n",
    "    if is_done:\n",
    "        break\n",
    "\n",
    "env.map.plot(ax=plt.gca())\n",
    "plt.plot(*zip(*env.agent.position_history), linewidth=2, color='black')\n",
    "plt.savefig('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-runs\n",
    "\n",
    "model = PPO.load('trail_model.zip', device='cpu')\n",
    "\n",
    "n_runs = 8\n",
    "headings = np.linspace(-np.pi / 7, np.pi / 7, num=n_runs)\n",
    "\n",
    "maps = []\n",
    "position_hists = []\n",
    "\n",
    "for heading in tqdm(headings):\n",
    "    trail_map = trail_class(**trail_args, heading=heading)\n",
    "    env = TrailEnv(trail_map, discrete=global_discrete, treadmill=global_treadmill)\n",
    "\n",
    "    obs = env.reset()\n",
    "    for _ in range(100):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, is_done, _ = env.step(action)\n",
    "\n",
    "        if is_done:\n",
    "            break\n",
    "    \n",
    "    maps.append(trail_map)\n",
    "    position_hists.append(env.agent.position_history)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for ax, m, position_history in zip(axs.ravel(), maps, position_hists):\n",
    "    m.plot(ax=ax)\n",
    "    ax.plot(*zip(*position_history), linewidth=2, color='black')\n",
    "\n",
    "fig.suptitle('Sample of agent runs')\n",
    "fig.tight_layout()\n",
    "plt.savefig('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAD-CAM viz\n",
    "model = PPO.load('trail_model.zip', device='cpu')\n",
    "pi = model.policy\n",
    "all_actions = torch.arange(model.action_space.n)\n",
    "\n",
    "trail_map = trail_class(**trail_args, heading=0)\n",
    "env = TrailEnv(trail_map, discrete=global_discrete, treadmill=global_treadmill)\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_probs(obs, ax):\n",
    "    obs_t, _ = pi.obs_to_tensor(obs)\n",
    "    value, probs, _ = pi.evaluate_actions(obs_t, all_actions)\n",
    "\n",
    "    ax.bar(['left', 'forward', 'right'], np.exp(probs), alpha=0.7)\n",
    "    return value\n",
    "\n",
    "class VisualPolicy(torch.nn.Module):\n",
    "    def __init__(self, pi):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "\n",
    "    def forward(self, obs):\n",
    "        _, probs, _ = self.pi.evaluate_actions(obs, all_actions)\n",
    "        return probs.unsqueeze(0)\n",
    "\n",
    "\n",
    "cam = GradCAM(\n",
    "    model=VisualPolicy(pi),\n",
    "    target_layers=[pi.features_extractor.cnn[5]]\n",
    ")\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, is_done, _ = env.step(action)\n",
    "    print(reward)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.imshow(obs)\n",
    "\n",
    "    obs_t, _ = pi.obs_to_tensor(obs)\n",
    "    grayscale_cam = cam(input_tensor=obs_t, target_category=None)\n",
    "    ax1.imshow(grayscale_cam[0], alpha=0.5, cmap='bone')\n",
    "\n",
    "    ax2 = plt.subplot(122)\n",
    "    value = plot_probs(obs, ax2)\n",
    "\n",
    "    ax1.set_title(f'State value: {value.numpy()[0,0]:.2f}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if is_done:\n",
    "        print('done')\n",
    "        break\n",
    "\n",
    "env.map.plot(ax=plt.gca())\n",
    "plt.plot(*zip(*env.agent.position_history), linewidth=2, color='black')\n",
    "plt.savefig('out.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
